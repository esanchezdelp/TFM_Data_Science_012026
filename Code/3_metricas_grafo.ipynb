{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["m8Cgp1hBhjVo","kKWiqTX5nNde","Y19jVAl65MrE","oPWbGD0MZmD6"],"authorship_tag":"ABX9TyPf8bxK8AMVGzM9cA6wv/Jw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Montar Drive + Imports"],"metadata":{"id":"d2TlyT-BIqm0"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","from typing import Dict, Any, List, Union\n","import pandas as pd\n","from tqdm import tqdm\n","import numpy as np\n","import networkx as nx\n","import warnings\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from scipy.stats import shapiro, levene, f_oneway, ttest_ind, mannwhitneyu, kruskal\n","from itertools import combinations"],"metadata":{"id":"pZcTGkItIux1","executionInfo":{"status":"ok","timestamp":1765267009105,"user_tz":-60,"elapsed":4242,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 1. Montar Google Drive\n","print(\"Paso 1: Montando Google Drive...\")\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Máster - Data Science/TFM/Data/ESTUDIO_MULTIPLEX')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVwKayKgIxmQ","executionInfo":{"status":"ok","timestamp":1765267037328,"user_tz":-60,"elapsed":28218,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}},"outputId":"3c4a49b3-a824-4825-81b9-10d8e5798041"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Paso 1: Montando Google Drive...\n","Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Función de recuperación de información + listar pacientes"],"metadata":{"id":"7oh45KnfJKXy"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"kZorMSwtIfV9","executionInfo":{"status":"ok","timestamp":1765267037361,"user_tz":-60,"elapsed":19,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"outputs":[],"source":["def obtener_datos_paciente(\n","    patient_id: str,\n","    base_dir: str = 'DADES_CORRECTED'\n",") -> Union[Dict[str, Any], None]:\n","    \"\"\"\n","    Recupera toda la información (clínica, nodos y redes) para un paciente\n","    dado su ID, a partir de la estructura de archivos en base_dir.\n","\n","    Args:\n","        patient_id: El ID del paciente (ej. 'P001').\n","        base_dir: El directorio base donde se encuentran los archivos.\n","\n","    Returns:\n","        Un diccionario con la información del paciente en el formato solicitado,\n","        o None si el ID del paciente no se encuentra.\n","    \"\"\"\n","\n","    # Rutas a los archivos\n","    clinic_file = os.path.join(base_dir, 'CLINIC.csv')\n","    nodes_vol_file = os.path.join(base_dir, 'NODES.csv')\n","    nodes_fa_file = os.path.join(base_dir, 'GM_FA.csv')\n","    nodes_md_file = os.path.join(base_dir, 'GM_MD.csv')\n","\n","    # 1. Recuperar información clínica\n","    try:\n","        df_clinic = pd.read_csv(clinic_file)\n","\n","        # Buscar la fila del paciente por su ID\n","        patient_data = df_clinic[df_clinic['ids'] == patient_id]\n","\n","        if patient_data.empty:\n","            print(f\"Error: ID de paciente '{patient_id}' no encontrado en CLINIC.csv.\")\n","            return None\n","\n","        # Extraer los datos (la fila es un DataFrame de 1xN, usamos .iloc[0] para obtener la Serie)\n","        patient_series = patient_data.iloc[0]\n","\n","    except FileNotFoundError:\n","        print(f\"Error: Archivo CLINIC.csv no encontrado en {base_dir}\")\n","        return None\n","\n","    # 2. Mapear y codificar la información clínica al formato solicitado\n","\n","    # El campo 'origenes' se usa para el campo 'origen' principal\n","    origen_data = str(patient_series['origenes'])\n","\n","    # El campo 'sites' se mapea a 'site' en la respuesta\n","    site_data = str(patient_series['sites'])\n","\n","    # Asumimos que los campos 'sexes', 'controls_mses' y 'mstypes' están\n","    # codificados como enteros o pueden ser convertidos a float/int.\n","    # Necesitarás definir la codificación de 'sexes' y 'mstypes' para el formato final,\n","    # aquí se usarán los valores tal cual están en el CSV (o se fuerza a int/float).\n","\n","    # Nota: Los nombres de las columnas ddes y edsses en el CSV anterior eran ddes y edsses\n","    # pero el formato solicitado pide 'dd' y 'edss'.\n","    info_clinica = {\n","        'id': str(patient_series['ids']),\n","        'age': float(patient_series['ages']),\n","        # Se asume una codificación para 'sexes', aquí se devuelve como está\n","        'sex': int(patient_series['sexes']) if pd.notna(patient_series['sexes']) else np.nan,\n","        'dd': float(patient_series['ddes']),\n","        'edss': float(patient_series['edsses']),\n","        'control_ms': int(patient_series['controls_mses']),\n","        # Se asume una codificación para 'mstypes' (0=RRMS, 1=SPMS, 2=PPMS)\n","        'mstype': int(patient_series['mstypes']) if pd.notna(patient_series['mstypes']) else np.nan\n","    }\n","\n","    # 3. Recuperar datos de nodos (nodos_volumetrico, nodos_FA, nodos_MD)\n","\n","    def load_node_data(file_path: str) -> List[float]:\n","        \"\"\"Carga y devuelve la lista de valores de nodo para el paciente.\"\"\"\n","        try:\n","            df_nodes = pd.read_csv(file_path)\n","            patient_row = df_nodes[df_nodes['ID'] == patient_id]\n","            if not patient_row.empty:\n","                # Excluir la columna 'ID' y convertir los valores a lista (float)\n","                return patient_row.iloc[0, 1:].tolist()\n","            else:\n","                return []\n","        except FileNotFoundError:\n","            print(f\"Advertencia: Archivo de nodos no encontrado: {file_path}\")\n","            return []\n","\n","    nodos_volumetrico = load_node_data(nodes_vol_file)\n","    nodos_FA = load_node_data(nodes_fa_file)\n","    nodos_MD = load_node_data(nodes_md_file)\n","\n","    # 4. Recuperar matrices de conectividad (redes)\n","\n","    redes = {}\n","    network_types = {'FA': 'FA_network', 'GM': 'GM_network', 'rsfmri': 'rsfmri_network'}\n","\n","    for net_key, net_dir in network_types.items():\n","        network_path = os.path.join(base_dir, net_dir, f\"{patient_id}.csv\")\n","        try:\n","            # Leer la matriz sin encabezados ni índice\n","            matrix = pd.read_csv(network_path, header=None, index_col=None).values\n","            redes[net_key] = matrix\n","        except FileNotFoundError:\n","            print(f\"Advertencia: Matriz {net_key} no encontrada para {patient_id} en {network_path}\")\n","            # Si una matriz falta, se puede optar por devolver un array vacío o None\n","            redes[net_key] = np.array([])\n","\n","    # 5. Consolidar el resultado\n","\n","    resultado = {\n","        'origen': origen_data,\n","        'site': site_data, # Incluir 'site' ya que está en los datos clínicos\n","        'info_clinica': info_clinica,\n","        'nodos_volumetrico': nodos_volumetrico,\n","        'nodos_FA': nodos_FA,\n","        'nodos_MD': nodos_MD,\n","        'redes': redes\n","    }\n","\n","    return resultado"]},{"cell_type":"code","source":["def listar_pacientes(base_dir: str = \".\") -> list[str]:\n","    \"\"\"\n","    Devuelve una lista con todos los valores de 'id_paciente' del archivo patients.csv.\n","\n","    Args:\n","        base_dir (str): Carpeta base donde se encuentra patients.csv\n","\n","    Returns:\n","        list[str]: Lista de IDs de pacientes.\n","    \"\"\"\n","    patients_path = os.path.join(base_dir, \"patients.csv\")\n","\n","    if not os.path.exists(patients_path):\n","        raise FileNotFoundError(f\"No se encontró el archivo: {patients_path}\")\n","\n","    df_patients = pd.read_csv(patients_path)\n","\n","    if \"id_paciente\" not in df_patients.columns:\n","        raise ValueError(\"El archivo patients.csv no contiene la columna 'id_paciente'.\")\n","\n","    # Elimina valores nulos y los convierte a string\n","    ids = df_patients[\"id_paciente\"].dropna().astype(str).tolist()\n","\n","    return ids\n","\n","pacientes = listar_pacientes()"],"metadata":{"id":"6yWdgl2PJUPQ","executionInfo":{"status":"ok","timestamp":1765267038653,"user_tz":-60,"elapsed":1290,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Cargar los datos"],"metadata":{"id":"8wm3NHGe-KIE"}},{"cell_type":"markdown","source":["Obtenemos los datos en formato tensorial para procesarlos luego:\n","\n","- `FA_matrices_tensor[i][j]`, `GM_matrices_tensor[i][j]` y `rsfMRI_matrices_tensor[i][j]` → lista de longitud `n_pacientes` con todos los valores de la conexión `(i,j)` para todos los pacientes.\n","\n","- `nodos_volumetricos_tensor[k]`, `nodos_FA_tensor[k]` y `nodos_MD_tensor[k]` → listas de valores por nodo `k` para todos los pacientes.\n","\n","- `origen`, `ages`, `sexes`, `ddes`, `edsses`, `control_mses`, `mstypes`  → arrays con las variables clínicas.\n","\n","- `site`  → array con el protocolo de muestra (FIS, MSVIS o sub)"],"metadata":{"id":"6C9xxYiC-UOc"}},{"cell_type":"code","source":["# --- Obtener dimensiones base (suponiendo todos los pacientes tienen mismas dimensiones) ---\n","info_ref = obtener_datos_paciente(pacientes[0])\n","n_nodos = info_ref['redes']['FA'].shape[0]\n","\n","# --- Inicializar estructuras vacías ---\n","FA_matrices_tensor = [[[] for _ in range(n_nodos)] for _ in range(n_nodos)]\n","GM_matrices_tensor = [[[] for _ in range(n_nodos)] for _ in range(n_nodos)]\n","rsfMRI_matrices_tensor = [[[] for _ in range(n_nodos)] for _ in range(n_nodos)]\n","\n","nodos_volumetricos_tensor = [[] for _ in range(n_nodos)]\n","nodos_FA_tensor = [[] for _ in range(n_nodos)]\n","nodos_MD_tensor = [[] for _ in range(n_nodos)]\n","\n","# Variables clínicas\n","origenes = []\n","ids = []\n","sites = []\n","ages = []\n","sexes = []\n","ddes = []\n","edsses = []\n","controls_mses = []\n","mstypes = []\n","\n","# --- Iterar sobre pacientes ---\n","for paciente in tqdm(pacientes, desc=\"Construyendo tensores de conectividad\"):\n","    info = obtener_datos_paciente(paciente)\n","    redes = info['redes']\n","    clinica = info['info_clinica']\n","\n","    # Guardar variables clínicas\n","    origenes.append(info['origen'])\n","    ids.append(clinica['id'])\n","    sites.append(info['site'])\n","    ages.append(clinica['age'])\n","    sexes.append(clinica['sex'])\n","    controls_mses.append(clinica['control_ms'])\n","    ddes.append(clinica['dd'])\n","    edsses.append(clinica['edss'])\n","    mstypes.append(clinica['mstype'])\n","\n","    # --- Rellenar tensores de conectividad ---\n","    for i in range(n_nodos):\n","        for j in range(n_nodos):\n","            FA_matrices_tensor[i][j].append(redes['FA'][i, j])\n","            GM_matrices_tensor[i][j].append(redes['GM'][i, j])\n","            rsfMRI_matrices_tensor[i][j].append(redes['rsfmri'][i, j])\n","\n","    # --- Rellenar tensores de nodos ---\n","    for k in range(n_nodos):\n","        nodos_volumetricos_tensor[k].append(info['nodos_volumetrico'][k])\n","        nodos_FA_tensor[k].append(info['nodos_FA'][k])\n","        nodos_MD_tensor[k].append(info['nodos_MD'][k])\n","\n","\n","# Convertir a numpy\n","FA_matrices_tensor = np.array(FA_matrices_tensor) # Dimensión: (n_nodos, n_nodos, n_pacientes)\n","GM_matrices_tensor = np.array(GM_matrices_tensor)\n","rsfMRI_matrices_tensor = np.array(rsfMRI_matrices_tensor)\n","\n","nodos_volumetricos_tensor = np.array(nodos_volumetricos_tensor)\n","nodos_FA_tensor = np.array(nodos_FA_tensor)\n","nodos_MD_tensor = np.array(nodos_MD_tensor)\n","\n","\n","# Convertir edad y sexo a arrays NumPy\n","ages = np.array(ages)\n","sexes = np.array(sexes)\n","ddes = np.array(ddes)\n","edsses = np.array(edsses)\n","controls_mses = np.array(controls_mses)\n","mstypes = np.array(mstypes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uHFaiEwW-QWn","executionInfo":{"status":"ok","timestamp":1765267635975,"user_tz":-60,"elapsed":592467,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}},"outputId":"6a1d7c56-16af-4341-8065-14a6326bfc3b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Construyendo tensores de conectividad: 100%|██████████| 270/270 [09:40<00:00,  2.15s/it]\n"]}]},{"cell_type":"markdown","source":["# Cálculos 1-layer (global)"],"metadata":{"id":"m8Cgp1hBhjVo"}},{"cell_type":"code","source":["def calcular_metricas_grafo(matriz_conectividad):\n","    \"\"\"\n","    Calcula diversas métricas de un grafo a partir de su matriz de conectividad.\n","\n","    :param matriz_conectividad: numpy.ndarray, matriz de conectividad/pesos\n","                                donde nan indica ausencia de conexión.\n","                                Se asume un grafo no dirigido.\n","    :return: dict, diccionario con las métricas calculadas.\n","    \"\"\"\n","    if not isinstance(matriz_conectividad, np.ndarray):\n","        matriz_conectividad = np.array(matriz_conectividad)\n","\n","    # 1. Preprocesamiento: Convertir la matriz de conectividad a una\n","    #    matriz de adyacencia/pesos válida para NetworkX.\n","    #    - Los nan se reemplazan por 0, indicando \"sin arista\".\n","    #    - Se asume que los valores no nan son los pesos de las aristas.\n","\n","    # Crear una copia para no modificar la original\n","    adj_matrix = matriz_conectividad.copy()\n","\n","    # Reemplazar nan por 0. Esto crea la matriz de adyacencia (A[i,j] = 0 si no hay arista)\n","    # y maneja correctamente si el peso es 0 (que sí es una arista con peso 0).\n","    adj_matrix[np.isnan(adj_matrix)] = 0\n","\n","    # Forzar la matriz a ser simétrica para asumir un grafo no dirigido\n","    # (aunque esto puede cambiar si el grafo es dirigido)\n","    adj_matrix = np.maximum(adj_matrix, adj_matrix.T)\n","\n","    # Grafo basado en los pesos\n","    # 1. Aplicar la lógica: Si un valor es > 1, se convierte en 1.\n","    adj_matrix_fuerza = adj_matrix.copy()\n","    G_fuerza = nx.from_numpy_array(adj_matrix_fuerza, create_using=nx.Graph)\n","\n","    # Convertir pesos distintos de 0 en distancias inversas (1/w)\n","    adj_matrix[adj_matrix != 0] = 1.0 / adj_matrix[adj_matrix != 0]\n","\n","    # 2. Creación del objeto Grafo\n","    # Se crea un grafo ponderado (Weighted Graph) a partir de la matriz de adyacencia.\n","    # Los aristas con peso 0 (o nan original) no serán incluidas.\n","    G = nx.from_numpy_array(adj_matrix, create_using=nx.Graph)\n","\n","    # Eliminar aristas con peso 0 (si se deben considerar como \"no conexión\")\n","    # NetworkX crea aristas para A[i,j] > 0. Si A[i,j] = 0 (por el nan o por el valor original),\n","    # no se crea la arista, lo que es el comportamiento deseado.\n","\n","    # 3. Preparar para métricas que requieren que el grafo esté conectado\n","    #    (Longitud de Camino Característico, Eficiencia Global)\n","\n","    # Obtener el subgrafo conectado más grande (Large Connected Component - LCC)\n","    if nx.is_connected(G):\n","        LCC = G\n","    else:\n","        # Encontrar el subgrafo con más nodos\n","        componentes = list(nx.connected_components(G))\n","        if not componentes:\n","             # Grafo vacío o sin aristas\n","            warnings.warn(\"El grafo está vacío o no tiene aristas.\")\n","            return {\n","                \"Eficiencia global\": np.nan,\n","                \"Longitud de camino característico\": np.nan,\n","                \"Fuerza nodal promedio\": 0.0,\n","                \"Coeficiente de agrupamiento\": 0.0,\n","                \"Asortatividad\": np.nan,\n","                \"Transitividad\": 0.0,\n","                \"Modularidad\": np.nan\n","            }\n","\n","        nodos_lcc = max(componentes, key=len)\n","        LCC = G.subgraph(nodos_lcc).copy()\n","        warnings.warn(\"El grafo no está conectado. Las métricas de camino/distancia se calculan en la Componente Conectada más Grande (LCC).\")\n","\n","    N = G.number_of_nodes()\n","    N_lcc = LCC.number_of_nodes()\n","\n","    # 4. Cálculo de Métricas\n","    metricas = {}\n","\n","    # --- Métricas Globales de Distancia (requieren LCC) ---\n","    # NetworkX calcula las distancias usando los pesos ('weight') por defecto\n","\n","    # **Longitud de Camino Característico (Average Shortest Path Length)**\n","    # Mide el grado promedio de separación.\n","    if N_lcc > 1:\n","        # Se calcula en la LCC, ya que un grafo desconectado tiene una longitud infinita\n","        # NetworkX usa el peso para calcular la distancia.\n","        try:\n","             metricas[\"Longitud de camino característico\"] = nx.average_shortest_path_length(LCC, weight='weight')\n","        except nx.NetworkXNoPath:\n","             metricas[\"Longitud de camino característico\"] = np.nan # No hay camino entre algunos pares\n","    else:\n","        metricas[\"Longitud de camino característico\"] = 0.0\n","\n","    # **Eficiencia Global (Global Efficiency)**\n","    def global_efficiency_weighted(G, weight='weight'):\n","        nodes = list(G.nodes())\n","        N = len(nodes)\n","        if N <= 1:\n","            return 0.0\n","\n","        # Obtener todas las distancias ponderadas\n","        dist = dict(nx.all_pairs_dijkstra_path_length(G, weight=weight))\n","\n","        suma = 0\n","        for i in nodes:\n","            for j in nodes:\n","                if i != j:\n","                    d = dist[i].get(j, np.inf)\n","                    if d != np.inf:\n","                        suma += 1 / d\n","\n","        return suma / (N * (N - 1))\n","\n","    # E_global = 1/|V| * sum_{i!=j} (1/d_ij). Mide la eficiencia de comunicación.\n","    if N > 1:\n","        # Se puede calcular en el grafo completo (G), ignorando caminos infinitos (1/inf=0)\n","        # NetworkX calcula la eficiencia global, maneja desconexiones internamente.\n","        metricas[\"Eficiencia global\"] = global_efficiency_weighted(G, weight='weight')\n","    else:\n","        metricas[\"Eficiencia global\"] = 0.0\n","\n","    # --- Métricas de Grado y Fuerza ---\n","\n","    # **Fuerza Nodal Promedio (Average Node Strength)**\n","    # La fuerza de un nodo es la suma de los pesos de sus aristas (análogo al grado en grafos no ponderados).\n","    # Se calcula la suma de los pesos de las aristas (fuerza/strength) para cada nodo y luego se promedia.\n","    node_strengths = G_fuerza.degree(weight='weight')\n","    total_strength = sum(s for _, s in node_strengths)\n","    metricas[\"Fuerza nodal promedio\"] = total_strength / N if N > 0 else 0.0\n","\n","    # --- Métricas de Agrupamiento ---\n","\n","    # **Coeficiente de Agrupamiento (Clustering Coefficient)**\n","    metricas[\"Coeficiente de agrupamiento\"] = nx.average_clustering(G_fuerza, weight='weight')\n","\n","    # **Transitividad (Transitivity)**\n","    # Mide la probabilidad de que un triángulo exista en el grafo (Global Clustering).\n","    metricas[\"Transitividad\"] = nx.transitivity(G_fuerza)\n","\n","    # --- Métricas de Conectividad y Estructura ---\n","\n","    # **Asortatividad (Assortativity)**\n","    # Mide si los nodos se conectan preferentemente con nodos de grado similar.\n","    # En grafos ponderados, se usa la asortatividad de grado (ignorando pesos)\n","    try:\n","        metricas[\"Asortatividad\"] = nx.degree_assortativity_coefficient(G_fuerza, weight=\"weight\")\n","    except Exception:\n","        metricas[\"Asortatividad\"] = np.nan # Puede fallar en grafos muy pequeños o vacíos\n","\n","    # **Modularidad (Modularity)**\n","    # Mide la fuerza de la división de un grafo en módulos (comunidades).\n","    # Requiere encontrar las comunidades primero. Usamos el algoritmo de Louvain.\n","    try:\n","        # El algoritmo de Louvain busca la partición que maximiza la modularidad.\n","        # Usa el peso si está presente.\n","        comunidades = nx.community.louvain_communities(G_fuerza, weight='weight')\n","        # La modularidad se calcula en base a la partición encontrada\n","        metricas[\"Modularidad\"] = nx.community.modularity(G_fuerza, comunidades, weight='weight')\n","    except Exception as e:\n","        # Esto puede fallar si el grafo es trivial o muy disperso.\n","        metricas[\"Modularidad\"] = np.nan\n","        warnings.warn(f\"No se pudo calcular la Modularidad: {e}\")\n","\n","    # 5. Formato de Salida\n","    # Asegurar que todos los valores sean flotantes o NaN para consistencia\n","    for k, v in metricas.items():\n","        if isinstance(v, (int, np.integer)):\n","            metricas[k] = float(v)\n","        elif isinstance(v, (float, np.floating)):\n","            pass # Ya es un float/numpy float\n","        elif v is None:\n","            metricas[k] = np.nan\n","\n","    return metricas"],"metadata":{"id":"8am-K4BVhm3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcular_metricas_tensor(tensor, ids, nombre_salida, calcular_metricas_grafo):\n","    \"\"\"\n","    Itera por la tercera dimensión de un tensor (i, j, k),\n","    calcula métricas de grafo para cada matriz k y\n","    guarda los resultados en un CSV en formato:\n","\n","    id, metrica1, metrica2, ..., metrican\n","    \"\"\"\n","\n","    carpeta = \"METRICAS_GRAFO\"\n","    os.makedirs(carpeta, exist_ok=True)\n","\n","    resultados_fila = []\n","\n","    # tqdm envuelve la iteración para mostrar la barra de progreso\n","    for k in tqdm(range(tensor.shape[2]), desc=\"Calculando métricas\"):\n","        matriz = tensor[:, :, k]\n","        metricas = calcular_metricas_grafo(matriz)   # Diccionario\n","\n","        fila = {\"id\": ids[k]}\n","        fila.update(metricas)   # Añade cada métrica como columna\n","\n","        resultados_fila.append(fila)\n","\n","    df = pd.DataFrame(resultados_fila)\n","\n","    ruta_salida = os.path.join(carpeta, f\"{nombre_salida}.csv\")\n","    df.to_csv(ruta_salida, index=False)\n","\n","    print(f\"CSV guardado en: {ruta_salida}\")"],"metadata":{"id":"LadYxJSglCvu","executionInfo":{"status":"ok","timestamp":1765267678632,"user_tz":-60,"elapsed":21,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["calcular_metricas_tensor(GM_matrices_tensor, ids, \"GM_GLOBAL\", calcular_metricas_grafo)\n","calcular_metricas_tensor(FA_matrices_tensor, ids, \"FA_GLOBAL\", calcular_metricas_grafo)\n","calcular_metricas_tensor(rsfMRI_matrices_tensor, ids, \"rsfMRI_GLOBAL\", calcular_metricas_grafo)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVMrcC-ViOy9","executionInfo":{"status":"ok","timestamp":1764693315387,"user_tz":-60,"elapsed":422018,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}},"outputId":"a93c7475-87a2-4a47-cc03-ad94db23375a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\rCalculando métricas:   0%|          | 0/270 [00:00<?, ?it/s]/tmp/ipython-input-1214741562.py:70: UserWarning: El grafo no está conectado. Las métricas de camino/distancia se calculan en la Componente Conectada más Grande (LCC).\n","  warnings.warn(\"El grafo no está conectado. Las métricas de camino/distancia se calculan en la Componente Conectada más Grande (LCC).\")\n","Calculando métricas: 100%|██████████| 270/270 [02:41<00:00,  1.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/GM_GLOBAL.csv\n"]},{"output_type":"stream","name":"stderr","text":["Calculando métricas: 100%|██████████| 270/270 [01:52<00:00,  2.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/FA_GLOBAL.csv\n"]},{"output_type":"stream","name":"stderr","text":["Calculando métricas: 100%|██████████| 270/270 [02:28<00:00,  1.82it/s]"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/rsfMRI_GLOBAL.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Cálculos 1-layer (local)"],"metadata":{"id":"Y19jVAl65MrE"}},{"cell_type":"code","source":["def calcular_metricas_grafo_local(matriz_conectividad):\n","    \"\"\"\n","    Calcula diversas métricas de un grafo a partir de su matriz de conectividad.\n","\n","    Métricas calculadas a nivel nodal:\n","        - Fuerza Nodal (suma de pesos de aristas)\n","        - Grado Nodal (número de aristas)\n","        - Eficiencia Local\n","        - Centralidad de intermediación (betweenness)\n","        - Centralidad de cercanía (closeness)\n","\n","    :param matriz_conectividad: numpy.ndarray, matriz de conectividad/pesos\n","                                donde nan indica ausencia de conexión.\n","                                Se asume un grafo no dirigido.\n","    :return: dict, diccionario con las métricas calculadas (arrays de n nodos por métrica).\n","    \"\"\"\n","    if not isinstance(matriz_conectividad, np.ndarray):\n","        matriz_conectividad = np.array(matriz_conectividad)\n","\n","    # --- Preprocesamiento de Fuerza ---\n","    # 1. Copia y reemplazo de NaN por 0\n","    adj_fuerza = matriz_conectividad.copy()\n","    adj_fuerza[np.isnan(adj_fuerza)] = 0\n","\n","    # 2. Simetrización para grafo no dirigido\n","    adj_fuerza = np.maximum(adj_fuerza, adj_fuerza.T)\n","\n","    # Crear grafo con la FUERZA de conexión como 'weight'\n","    G_fuerza = nx.from_numpy_array(adj_fuerza, create_using=nx.Graph)\n","\n","    # --- Preprocesamiento de Distancia (para métricas de camino) ---\n","    adj_distancia = adj_fuerza.copy()\n","    # Invertir pesos: Distancia = 1 / Fuerza\n","    with np.errstate(divide='ignore'): # Ignorar división por cero (aristas con fuerza 0)\n","        adj_distancia[adj_distancia != 0] = 1.0 / adj_distancia[adj_distancia != 0]\n","\n","    # Crear grafo con la DISTANCIA como 'weight'\n","    G_distancia = nx.from_numpy_array(adj_distancia, create_using=nx.Graph)\n","\n","    # --- Cálculo de métricas ---\n","\n","    # Fuerza Nodal: suma de las FUERZAS de las aristas (usando G_fuerza)\n","    fuerza_nodal = np.array([d for n, d in G_fuerza.degree(weight='weight')])\n","\n","    # Grado Nodal: número de aristas conectadas a cada nodo (usando G_fuerza o G_distancia)\n","    grado_nodal = np.array([d for n, d in G_fuerza.degree()])\n","\n","    def calcular_eficiencia_local_nodal(G):\n","        \"\"\"\n","        Calcula la eficiencia local (E_i) para cada nodo i en el grafo G.\n","        E_i = eficiencia global del subgrafo inducido por los vecinos de i.\n","        Se calcula una sola vez todas las distancias y luego se usa para cada subgrafo.\n","        \"\"\"\n","\n","        nodes = list(G.nodes())\n","        N = len(nodes)\n","\n","        # 1. Calcular todas las distancias ponderadas una sola vez\n","        # Distancias entre todos los pares de nodos (peso = 'weight')\n","        dist_all = dict(nx.all_pairs_dijkstra_path_length(G, weight='weight'))\n","\n","        eficiencia_local_por_nodo = {}\n","\n","        for nodo_i in nodes:\n","            vecinos_i = list(G.neighbors(nodo_i))\n","\n","            if len(vecinos_i) < 2:\n","                eficiencia_local_por_nodo[nodo_i] = 0.0\n","                continue\n","\n","            # 2. Calcular eficiencia global del subgrafo inducido por los vecinos usando distancias precalculadas\n","            suma = 0.0\n","            for u in vecinos_i:\n","                for v in vecinos_i:\n","                    if u != v:\n","                        d = dist_all[u].get(v, np.inf)\n","                        if d != np.inf:\n","                            suma += 1 / d\n","\n","            k = len(vecinos_i)\n","            eficiencia_local_por_nodo[nodo_i] = suma / (k * (k - 1))\n","\n","        # Aseguramos el orden del array para que coincida con el orden de los nodos de NetworkX\n","        return np.array([eficiencia_local_por_nodo[n] for n in nodes])\n","\n","    eficiencia_local = calcular_eficiencia_local_nodal(G_distancia)\n","\n","\n","    # Centralidad de intermediación (betweenness)\n","    # distance='weight' usa los pesos del grafo (distancias)\n","    betweenness = np.array(list(nx.betweenness_centrality(G_distancia, weight='weight').values()))\n","\n","    # Centralidad de cercanía (closeness)\n","    # distance='weight' usa los pesos del grafo (distancias)\n","    closeness = np.array(list(nx.closeness_centrality(G_distancia, distance='weight').values()))\n","\n","    # --- Retornar resultados ---\n","    return {\n","        'fuerza_nodal': fuerza_nodal,\n","        'grado_nodal': grado_nodal,\n","        'eficiencia_local': eficiencia_local,\n","        'centralidad_intermediacion': betweenness,\n","        'centralidad_cercania': closeness\n","    }"],"metadata":{"id":"_tWryX-f9CcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcular_metricas_tensor_local_por_nodo(tensor, ids, nombre_salida, calcular_metricas_grafo_local):\n","    \"\"\"\n","    Itera por la tercera dimensión de un tensor (i, j, k),\n","    calcula métricas locales de grafo para cada matriz k y\n","    guarda los resultados en CSVs separados para cada métrica local.\n","\n","    El CSV tiene el formato:\n","        ID, nodo1, nodo2, ..., nodon\n","    \"\"\"\n","    carpeta = \"METRICAS_GRAFO\"\n","    os.makedirs(carpeta, exist_ok=True)\n","\n","    # Inicializamos diccionarios para cada métrica\n","    metricas_dict = {}\n","\n","    for k in tqdm(range(tensor.shape[2]), desc=\"Procesando matrices\"):\n","        matriz = tensor[:, :, k]\n","        metricas = calcular_metricas_grafo_local(matriz)  # Diccionario de arrays (nodos)\n","\n","        for nombre, valores in metricas.items():\n","            if nombre not in metricas_dict:\n","                metricas_dict[nombre] = []\n","            # Añadimos una fila: [ID, val_nodo1, val_nodo2, ...]\n","            metricas_dict[nombre].append([ids[k]] + list(valores))\n","\n","    # Guardar cada métrica en un CSV separado\n","    for nombre, filas in metricas_dict.items():\n","        df = pd.DataFrame(filas)\n","        # Nombres de columnas: ID + nodo1, nodo2, ...\n","        n_nodos = tensor.shape[0]\n","        columnas = ['ID'] + [f'nodo{i+1}' for i in range(n_nodos)]\n","        df.columns = columnas\n","\n","        ruta_salida = os.path.join(carpeta, f\"{nombre}_{nombre_salida}.csv\")\n","        df.to_csv(ruta_salida, index=False)\n","        print(f\"CSV guardado en: {ruta_salida}\")"],"metadata":{"id":"WE2quQhA-wPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calcular_metricas_tensor_local_por_nodo(GM_matrices_tensor, ids, \"GM_LOCAL\", calcular_metricas_grafo_local)\n","calcular_metricas_tensor_local_por_nodo(FA_matrices_tensor, ids, \"FA_LOCAL\", calcular_metricas_grafo_local)\n","calcular_metricas_tensor_local_por_nodo(rsfMRI_matrices_tensor, ids, \"rsfMRI_LOCAL\", calcular_metricas_grafo_local)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjHySs94MZvq","executionInfo":{"status":"ok","timestamp":1764693686420,"user_tz":-60,"elapsed":370973,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}},"outputId":"6c571f99-0687-44e9-c26d-8a4ba693d238"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Procesando matrices: 100%|██████████| 270/270 [02:20<00:00,  1.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/fuerza_nodal_GM_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/grado_nodal_GM_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/eficiencia_local_GM_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_intermediacion_GM_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_cercania_GM_LOCAL.csv\n"]},{"output_type":"stream","name":"stderr","text":["Procesando matrices: 100%|██████████| 270/270 [01:41<00:00,  2.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/fuerza_nodal_FA_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/grado_nodal_FA_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/eficiencia_local_FA_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_intermediacion_FA_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_cercania_FA_LOCAL.csv\n"]},{"output_type":"stream","name":"stderr","text":["Procesando matrices: 100%|██████████| 270/270 [02:07<00:00,  2.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/fuerza_nodal_rsfMRI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/grado_nodal_rsfMRI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/eficiencia_local_rsfMRI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_intermediacion_rsfMRI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_cercania_rsfMRI_LOCAL.csv\n"]}]},{"cell_type":"markdown","source":["# Cálculos Multi-Layer (global)"],"metadata":{"id":"IHIOl48kt89-"}},{"cell_type":"code","source":["def combinar_tensores(t1, t2, t3):\n","    \"\"\"\n","    t1, t2, t3: tensores de tamaño (n_nodos, n_nodos, n_pacientes)\n","\n","    Devuelve:\n","        tensor_out de tamaño (2*n_nodos, 2*n_nodos, n_pacientes)\n","        tal que para cada paciente p:\n","\n","            ( t1[:,:,p]   t2[:,:,p] )\n","            ( t2[:,:,p]   t3[:,:,p] )\n","    \"\"\"\n","\n","    n_nodos, _, n_pacientes = t1.shape\n","\n","    # Tensor de salida\n","    out = np.zeros((2*n_nodos, 2*n_nodos, n_pacientes))\n","\n","    # Rellenar bloques\n","    out[:n_nodos, :n_nodos, :] = t1\n","    out[:n_nodos, n_nodos:, :] = t2\n","    out[n_nodos:, :n_nodos, :] = t2\n","    out[n_nodos:, n_nodos:, :] = t3\n","\n","    return out"],"metadata":{"id":"94rqbshOn4W2","executionInfo":{"status":"ok","timestamp":1765267688251,"user_tz":-60,"elapsed":7,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["multilayer_matrices_tensor = combinar_tensores(GM_matrices_tensor, FA_matrices_tensor, rsfMRI_matrices_tensor)"],"metadata":{"id":"W8j0PpzirGmJ","executionInfo":{"status":"ok","timestamp":1765267688341,"user_tz":-60,"elapsed":87,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def calcular_metricas_multigrafo(matriz_conectividad):\n","    \"\"\"\n","    Calcula diversas métricas de un grafo a partir de su matriz de conectividad.\n","\n","    :param matriz_conectividad: numpy.ndarray, matriz de conectividad/pesos\n","                                donde nan indica ausencia de conexión.\n","                                Se asume un grafo no dirigido.\n","    :return: dict, diccionario con las métricas calculadas.\n","    \"\"\"\n","    if not isinstance(matriz_conectividad, np.ndarray):\n","        matriz_conectividad = np.array(matriz_conectividad)\n","\n","    # 1. Preprocesamiento: Convertir la matriz de conectividad a una\n","    #    matriz de adyacencia/pesos válida para NetworkX.\n","    #    - Los nan se reemplazan por 0, indicando \"sin arista\".\n","    #    - Se asume que los valores no nan son los pesos de las aristas.\n","\n","    # Crear una copia para no modificar la original\n","    adj_matrix = matriz_conectividad.copy()\n","\n","    # Reemplazar nan por 0. Esto crea la matriz de adyacencia (A[i,j] = 0 si no hay arista)\n","    # y maneja correctamente si el peso es 0 (que sí es una arista con peso 0).\n","    adj_matrix[np.isnan(adj_matrix)] = 0\n","\n","    # Forzar la matriz a ser simétrica para asumir un grafo no dirigido\n","    # (aunque esto puede cambiar si el grafo es dirigido)\n","    adj_matrix = np.maximum(adj_matrix, adj_matrix.T)\n","\n","    # Grafo basado en los pesos\n","    adj_matrix_fuerza = adj_matrix.copy()\n","    G_fuerza = nx.from_numpy_array(adj_matrix_fuerza, create_using=nx.Graph)\n","\n","    # Convertir pesos distintos de 0 en distancias inversas (1/w)\n","    adj_matrix[adj_matrix != 0] = 1.0 / adj_matrix[adj_matrix != 0]\n","\n","    # 2. Creación del objeto Grafo\n","    # Se crea un grafo ponderado (Weighted Graph) a partir de la matriz de adyacencia.\n","    # Los aristas con peso 0 (o nan original) no serán incluidas.\n","    G = nx.from_numpy_array(adj_matrix, create_using=nx.Graph)\n","\n","    # Eliminar aristas con peso 0 (si se deben considerar como \"no conexión\")\n","    # NetworkX crea aristas para A[i,j] > 0. Si A[i,j] = 0 (por el nan o por el valor original),\n","    # no se crea la arista, lo que es el comportamiento deseado.\n","\n","    # 3. Preparar para métricas que requieren que el grafo esté conectado\n","    #    (Longitud de Camino Característico, Eficiencia Global)\n","\n","    # Obtener el subgrafo conectado más grande (Large Connected Component - LCC)\n","    if nx.is_connected(G):\n","        LCC = G\n","    else:\n","        # Encontrar el subgrafo con más nodos\n","        componentes = list(nx.connected_components(G))\n","        if not componentes:\n","             # Grafo vacío o sin aristas\n","            warnings.warn(\"El grafo está vacío o no tiene aristas.\")\n","            return {\n","                \"Eficiencia global\": np.nan,\n","                \"Longitud de camino característico\": np.nan,\n","                \"Fuerza nodal promedio\": 0.0,\n","                \"Coeficiente de agrupamiento\": 0.0,\n","                \"Asortatividad\": np.nan,\n","                \"Transitividad\": 0.0,\n","                \"Modularidad\": np.nan\n","            }\n","\n","        nodos_lcc = max(componentes, key=len)\n","        LCC = G.subgraph(nodos_lcc).copy()\n","        warnings.warn(\"El grafo no está conectado. Las métricas de camino/distancia se calculan en la Componente Conectada más Grande (LCC).\")\n","\n","    N = G.number_of_nodes()\n","    N_lcc = LCC.number_of_nodes()\n","\n","    # 4. Cálculo de Métricas\n","    metricas = {}\n","\n","    # --- Métricas Globales de Distancia (requieren LCC) ---\n","    # NetworkX calcula las distancias usando los pesos ('weight') por defecto\n","\n","    # **Longitud de Camino Característico (Average Shortest Path Length)**\n","    # Mide el grado promedio de separación.\n","    n_nodos = LCC.number_of_nodes()//2\n","    # 1️⃣ Calcular todas las distancias usando Dijkstra\n","    dist_dict = dict(nx.all_pairs_dijkstra_path_length(LCC, weight='weight'))\n","\n","    # 2️⃣ Inicializar la matriz de distancias completas\n","    dist_matrix = np.full((N, N), np.inf)\n","    nodes = list(LCC.nodes())\n","    node_index = {node: idx for idx, node in enumerate(nodes)}\n","\n","    for u, lengths in dist_dict.items():\n","        i = node_index[u]\n","        for v, d in lengths.items():\n","            j = node_index[v]\n","            dist_matrix[i, j] = d\n","\n","    # 3️⃣ Construir la matriz mínima considerando el nodo duplicado\n","    # En verdad es innecesario ya que si se pone que la distancia de\n","    # nodo a nodo (i a i) entre capas es 0 entonces es lo mismo\n","    dist_matrix_min = np.minimum(\n","        dist_matrix[:n_nodos, :n_nodos],      # original\n","        dist_matrix[:n_nodos, n_nodos:2*n_nodos]  # duplicada\n","    )\n","\n","    # 4️⃣ Calcular la longitud promedio del camino más corto\n","    finite_distances = dist_matrix_min[np.isfinite(dist_matrix_min)]\n","    if len(finite_distances) > 0:\n","        metricas[\"Longitud de camino característico\"] = np.mean(finite_distances)\n","    else:\n","        metricas[\"Longitud de camino característico\"] = np.nan\n","\n","    # **Eficiencia Global (Global Efficiency)**\n","    def global_efficiency_weighted(dist_matrix_min, n_nodos):\n","        # Calcular eficiencia global\n","        suma = 0\n","        for i in range(n_nodos):\n","            for j in range(n_nodos):\n","                if i != j and np.isfinite(dist_matrix_min[i, j]):\n","                    suma += 1 / dist_matrix_min[i, j]\n","\n","        return suma / (n_nodos * (n_nodos - 1))\n","\n","    # E_global = 1/|V| * sum_{i!=j} (1/d_ij). Mide la eficiencia de comunicación.\n","    if N > 1:\n","        # Se puede calcular en el grafo completo (G), ignorando caminos infinitos (1/inf=0)\n","        # NetworkX calcula la eficiencia global, maneja desconexiones internamente.\n","        metricas[\"Eficiencia global\"] = global_efficiency_weighted(dist_matrix_min, n_nodos)\n","    else:\n","        metricas[\"Eficiencia global\"] = 0.0\n","\n","    # --- Métricas de Fuerza ---\n","\n","    # **Fuerza Nodal Promedio (Average Node Strength)**\n","    # La fuerza de un nodo es la suma de los pesos de sus aristas (análogo al grado en grafos no ponderados).\n","    # Se calcula la suma de los pesos de las aristas (fuerza/strength) para cada nodo y luego se promedia.\n","    node_strengths = G_fuerza.degree(weight='weight')\n","    total_strength = sum(s for _, s in node_strengths)\n","    metricas[\"Fuerza nodal promedio\"] = total_strength / N if N > 0 else 0.0\n","\n","\n","    # --- Métricas de Agrupamiento ---\n","\n","    # **Coeficiente de Agrupamiento (Clustering Coefficient)**\n","    # Basado en Onnela (2005) pero el número posible de enlaces es k_i(k_i-1)/2\n","    # y también los interlayer que son k_i*k_j si es unilayer y w=1 es cálculo\n","    # clásico\n","\n","    def multilayer_clustering_transitivity(G, n_nodos, weight='weight'):\n","        \"\"\"\n","        Calcula el clustering y la transitividad de un grafo multilayer ponderado.\n","\n","        Parámetros:\n","        - G (nx.Graph): Grafo multicapa. Nodos esperados: (nodo_base, capa).\n","        - n_nodos (int): Número de nodos base.\n","        - weight (str): Nombre del atributo de peso de los enlaces. Por defecto 'weight'.\n","\n","        Retorna:\n","        - metricas (dict): Diccionario con el clustering promedio y la transitividad.\n","        \"\"\"\n","\n","        clustering_values = []\n","        total_triangles = 0\n","        total_triplets = 0\n","\n","\n","        # Recorremos cada nodo base\n","        for i in range(n_nodos):\n","            # Nodo en la capa 0 e nodo en la capa 1\n","            node0 = i\n","            node1 = i + n_nodos\n","\n","            neighbors0 = list(G.neighbors(node0))\n","            neighbors1 = list(G.neighbors(node1))\n","\n","            # Función auxiliar para calcular el clustering ponderado de un nodo dado\n","            def weighted_clustering_for_node(node, neighbors):\n","                triangles = 0.0\n","                ti = 0\n","                for u, v in combinations(neighbors, 2):\n","                    if G.has_edge(u, v):\n","                        w_uv = G[u][v].get(weight, 1.0)\n","                        w_nu = G[node][u].get(weight, 1.0)\n","                        w_nv = G[node][v].get(weight, 1.0)\n","                        triangles += (w_nu * w_nv * w_uv) ** (1/3)\n","                        ti += 1\n","                if len(neighbors) < 2:\n","                    return 0\n","                return triangles, ti\n","\n","            # Clustering intralayer\n","            c0, t0 = weighted_clustering_for_node(node0, neighbors0)\n","            c1, t1 = weighted_clustering_for_node(node1, neighbors1)\n","\n","            # Clustering interlayer: vecinos de node0 con vecinos de node1\n","            triangles_inter = 0.0\n","            t_inter = 0\n","            for u in neighbors0:\n","                for v in neighbors1:\n","                    if G.has_edge(u, v):\n","                        w_uv = G[u][v].get(weight, 1.0)\n","                        w_nu = G[node0][u].get(weight, 1.0)\n","                        w_nv = G[node1][v].get(weight, 1.0)\n","                        triangles_inter += (w_nu * w_nv * w_uv) ** (1/3)\n","                        t_inter += 1\n","            c_inter = triangles_inter if neighbors0 and neighbors1 else 0\n","\n","            # Promediamos los tres componentes\n","            clustering_values.append((c0 + c1 + c_inter)/(len(neighbors0)*len(neighbors1) + len(neighbors0)*(len(neighbors0)-1)/2 + len(neighbors1)*(len(neighbors1)-1)/2))\n","\n","            # --- Transitividad no ponderada ---\n","            # Triángulos intralayer\n","            t0 = sum(1 for u, v in combinations(neighbors0, 2) if G.has_edge(u, v))\n","            t1 = sum(1 for u, v in combinations(neighbors1, 2) if G.has_edge(u, v))\n","            trip0 = len(neighbors0) * (len(neighbors0) - 1) / 2\n","            trip1 = len(neighbors1) * (len(neighbors1) - 1) / 2\n","\n","            total_triangles += t0 + t1 + t_inter\n","            total_triplets += (len(neighbors0)*len(neighbors1) + len(neighbors0)*(len(neighbors0)-1)/2 + len(neighbors1)*(len(neighbors1)-1)/2)\n","\n","        avg_clustering = sum(clustering_values)/len(clustering_values) if clustering_values else 0\n","        transitivity_global = (3 * total_triangles / total_triplets) if total_triplets > 0 else 0\n","\n","        return avg_clustering, transitivity_global\n","\n","    # **Transitividad (Transitivity)**\n","    # Mide la probabilidad de que un triángulo exista en el grafo (Global Clustering).\n","\n","    metricas[\"Coeficiente de agrupamiento\"], metricas[\"Transitividad\"] = multilayer_clustering_transitivity(G_fuerza, n_nodos, weight='weight')\n","\n","    # --- Métricas de Conectividad y Estructura ---\n","\n","    # **Asortatividad (Assortativity)**\n","    def manual_degree_assortativity(G, weight=None):\n","        \"\"\"\n","        Calcula la asortatividad por grado (ponderada o no)\n","        sin usar las funciones de assortativity de NetworkX.\n","        \"\"\"\n","\n","        # --- Obtener la lista de grados ---\n","        degrees_init = dict(G.degree())\n","\n","        # Calcular el degree a nivel nodal como suma total\n","\n","        degrees = {}\n","\n","        for i in range(n_nodos):\n","            valor = degrees_init[i] + degrees_init[i + n_nodos]\n","            degrees[i] = valor\n","            degrees[i + n_nodos] = valor\n","\n","        # --- Preparar sumatorias ---\n","        sum_w = 0.0              # suma de pesos totales (o número de aristas si no hay peso)\n","        sum_jk = 0.0             # sumatoria de j_i k_i w_i\n","        sum_j2k2 = 0.0           # sumatoria de (j_i^2 + k_i^2)/2 * w_i\n","        sum_jk_avg2 = 0.0        # sumatoria de ((j_i + k_i)^2)/2 * w_i\n","\n","        # --- Recorrer aristas ---\n","        for u, v, data in G.edges(data=True):\n","\n","            # obtener peso si corresponde\n","            w = data.get(weight, 1.0) if weight is not None else 1.0\n","\n","            j = degrees[u]\n","            k = degrees[v]\n","\n","            sum_w += w\n","            sum_jk += w * j * k\n","            sum_j2k2 += w * (j**2 + k**2) / 2\n","            sum_jk_avg2 += w * (j + k)**2 / 2\n","\n","        # --- Fórmula de Newman (NetworkX la implementa así) ---\n","        num = sum_jk - (sum_jk_avg2 / sum_w)\n","        den = sum_j2k2 - (sum_jk_avg2 / sum_w)\n","\n","        if den == 0:\n","            return 0  # o NaN, como prefieras\n","\n","        return num / den\n","\n","    # Mide si los nodos se conectan preferentemente con nodos de grado similar.\n","    # En grafos ponderados, se usa la asortatividad de grado (ignorando pesos)\n","    try:\n","        metricas[\"Asortatividad\"] = manual_degree_assortativity(G_fuerza, weight=\"weight\")\n","    except Exception:\n","        metricas[\"Asortatividad\"] = np.nan # Puede fallar en grafos muy pequeños o vacíos\n","\n","    # **Modularidad (Modularity)**\n","    # Proyectamos sobre un grafo unilayer que tenga las conexiones múltiples\n","    # como el promedio de ellas\n","    def proyectar_grafo(G_fuerza, n_nodos):\n","        G_proy = nx.Graph()\n","\n","        # 1. Crear el grafo proyectado con todos los nodos\n","        for i in range(n_nodos):\n","            G_proy.add_node(i)\n","\n","        # 2. Recorrer todos los pares de nodos base (u, v)\n","        for u in range(n_nodos):\n","            for v in range(u + 1, n_nodos):\n","                # Acumulador de fuerza\n","                fuerza = 0.0\n","\n","                # Contribución de la Capa 0 (u -> v)\n","                if G_fuerza.has_edge(u, v):\n","                    fuerza += G_fuerza[u][v].get('weight', 0)\n","\n","                # Contribución de la Capa 1 (u+n -> v+n)\n","                if G_fuerza.has_edge(u + n_nodos, v + n_nodos):\n","                    fuerza += G_fuerza[u + n_nodos][v + n_nodos].get('weight', 0)\n","\n","                # Contribución Inter-Capa (u -> v+n y v -> u+n)\n","                if G_fuerza.has_edge(u, v + n_nodos):\n","                    fuerza += G_fuerza[u][v + n_nodos].get('weight', 0)\n","                if G_fuerza.has_edge(v, u + n_nodos):\n","                    fuerza += G_fuerza[v][u + n_nodos].get('weight', 0)\n","\n","                # 3. Añadir la arista al grafo proyectado si hay alguna fuerza\n","                if fuerza > 0:\n","                    G_proy.add_edge(u, v, weight=fuerza)\n","\n","        return G_proy\n","\n","    G_fuerza_proy = proyectar_grafo(G_fuerza, n_nodos)\n","\n","\n","    # Mide la fuerza de la división de un grafo en módulos (comunidades).\n","    # Requiere encontrar las comunidades primero. Usamos el algoritmo de Louvain.\n","    try:\n","        # El algoritmo de Louvain busca la partición que maximiza la modularidad.\n","        # Usa el peso si está presente.\n","        comunidades = nx.community.louvain_communities(G_fuerza_proy, weight='weight')\n","        # La modularidad se calcula en base a la partición encontrada\n","        metricas[\"Modularidad\"] = nx.community.modularity(G_fuerza_proy, comunidades, weight='weight')\n","    except Exception as e:\n","        # Esto puede fallar si el grafo es trivial o muy disperso.\n","        metricas[\"Modularidad\"] = np.nan\n","        warnings.warn(f\"No se pudo calcular la Modularidad: {e}\")\n","\n","    # 5. Formato de Salida\n","    # Asegurar que todos los valores sean flotantes o NaN para consistencia\n","    for k, v in metricas.items():\n","        if isinstance(v, (int, np.integer)):\n","            metricas[k] = float(v)\n","        elif isinstance(v, (float, np.floating)):\n","            pass # Ya es un float/numpy float\n","        elif v is None:\n","            metricas[k] = np.nan\n","\n","    return metricas"],"metadata":{"id":"MrUl6MnZCkou","executionInfo":{"status":"ok","timestamp":1765267688374,"user_tz":-60,"elapsed":16,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["calcular_metricas_tensor(multilayer_matrices_tensor, ids, \"MULTI_GLOBAL\", calcular_metricas_multigrafo)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wL6lNjAYEEf","executionInfo":{"status":"ok","timestamp":1765268861142,"user_tz":-60,"elapsed":1172766,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}},"outputId":"9adfd9ad-4d1f-4edf-f1b0-9da0cc68c47c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Calculando métricas: 100%|██████████| 270/270 [19:32<00:00,  4.34s/it]"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/MULTI_GLOBAL.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Calculos Multilayer (Local)"],"metadata":{"id":"oPWbGD0MZmD6"}},{"cell_type":"code","source":["calcular_metricas_tensor_local_por_nodo(multilayer_matrices_tensor, ids, \"MULTI_LOCAL\", calcular_metricas_grafo_local)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0yOMpQLZpWm","executionInfo":{"status":"ok","timestamp":1765035628014,"user_tz":-60,"elapsed":1211312,"user":{"displayName":"Edgar Sánchez del Pozo","userId":"12870838118909161960"}},"outputId":"fb25ddfd-f529-4a99-b6d4-8079fbb33731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Procesando matrices: 100%|██████████| 270/270 [20:10<00:00,  4.48s/it]\n"]},{"output_type":"stream","name":"stdout","text":["CSV guardado en: METRICAS_GRAFO/fuerza_nodal_MULTI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/grado_nodal_MULTI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/eficiencia_local_MULTI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_intermediacion_MULTI_LOCAL.csv\n","CSV guardado en: METRICAS_GRAFO/centralidad_cercania_MULTI_LOCAL.csv\n"]}]}]}